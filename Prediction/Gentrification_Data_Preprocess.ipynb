{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhargavilanka/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/bhargavilanka/opt/anaconda3/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/bhargavilanka/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# imports / libraries used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('All_Data_Gentrification.csv').iloc[:, 1:]\n",
    "test = pd.read_csv('All_Gentrification_Test.csv').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 3:-1]\n",
    "y_train = train.iloc[:, -1:]\n",
    "X_test = test.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric columns\n",
    "train_numeric  = X_train.iloc[:, :-2]\n",
    "test_numeric  = X_test.iloc[:, :-2]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_train = scaler.fit_transform(train_numeric)\n",
    "scaled_train = np.nan_to_num(scaled_train, nan=0.0)\n",
    "\n",
    "scaled_test = scaler.fit_transform(test_numeric)\n",
    "scaled_test = np.nan_to_num(scaled_test, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text  = X_train.iloc[:, -2:]\n",
    "test_text  = X_test.iloc[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for 'Vibe', shape: (1302, 384)\n",
      "Generated embeddings for 'Activities', shape: (1302, 384)\n",
      "Combined embeddings shape: (1302, 768)\n",
      "Generated embeddings for 'Vibe', shape: (76, 384)\n",
      "Generated embeddings for 'Activities', shape: (76, 384)\n",
      "Combined embeddings shape: (76, 768)\n"
     ]
    }
   ],
   "source": [
    "# generate embeddings for text data\n",
    "train_text  = X_train.iloc[:, -2:]\n",
    "test_text  = X_test.iloc[:, -2:]\n",
    "\n",
    "# generate embeddings for the data with Sentence-Bert since we have full sentences and need context\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "text_embeddings_train = {}\n",
    "\n",
    "for col in train_text.columns:\n",
    "    col_texts = train_text[col].astype(str).tolist()\n",
    "    text_embeddings_train[col] = model.encode(col_texts)\n",
    "    print(f\"Generated embeddings for '{col}', shape: {text_embeddings_train[col].shape}\")\n",
    "\n",
    "# combine embeddings from both columns so both can be used in clustering\n",
    "all_embeddings_train = np.hstack([text_embeddings_train['Vibe'], text_embeddings_train['Activities']])\n",
    "print(f\"Combined embeddings shape: {all_embeddings_train.shape}\")\n",
    "\n",
    "# standardize the embeddings\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings_train = scaler.fit_transform(all_embeddings_train)\n",
    "\n",
    "\n",
    "text_embeddings_test = {}\n",
    "\n",
    "for col in test_text.columns:\n",
    "    col_texts = test_text[col].astype(str).tolist()\n",
    "    text_embeddings_test[col] = model.encode(col_texts)\n",
    "    print(f\"Generated embeddings for '{col}', shape: {text_embeddings_test[col].shape}\")\n",
    "\n",
    "# combine embeddings from both columns so both can be used in clustering\n",
    "all_embeddings_test = np.hstack([text_embeddings_test['Vibe'], text_embeddings_test['Activities']])\n",
    "print(f\"Combined embeddings shape: {all_embeddings_test.shape}\")\n",
    "\n",
    "# standardize the embeddings\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings_test = scaler.fit_transform(all_embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(np.hstack([scaled_train, scaled_embeddings_train]))\n",
    "X_test = pd.DataFrame(np.hstack([scaled_test, scaled_embeddings_test]))\n",
    "\n",
    "X_train.to_csv(\"X_train.csv\")\n",
    "X_test.to_csv(\"X_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
